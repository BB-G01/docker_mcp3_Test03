version: '3.8'

# ─── Common Logging Settings ───────────────────────────────
x-common-logging: &common-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

# ─── Ollama Base Configuration ─────────────────────────────
x-ollama-base: &ollama-base
  image: ollama/ollama:latest
  volumes:
    - ollama_data:/root/.ollama
  logging: *common-logging
  restart: unless-stopped
  env_file:
    - .env

services:
  # Concept Explanation Agent (Llama3 8B)
  agent_a:
    <<: *ollama-base
    container_name: ai_agent_a
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_MODEL=llama3:8b
    deploy:
      resources:
        limits:
          memory: "8g"
          cpus: "2"

  # Code Example Agent (DeepSeek-Coder 6.7B)
  agent_b:
    <<: *ollama-base
    container_name: ai_agent_b
    ports:
      - "11435:11434"
    environment:
      - OLLAMA_MODEL=deepseek-coder:6.7b
    deploy:
      resources:
        limits:
          memory: "8g"
          cpus: "2"

  # Interactive Feedback Agent (Phi3 Mini)
  agent_c:
    <<: *ollama-base
    container_name: ai_agent_c
    ports:
      - "11436:11434"
    environment:
      - OLLAMA_MODEL=phi3:mini
    deploy:
      resources:
        limits:
          memory: "4g"
          cpus: "1"

  # GPT-O4-Mini Agent (Lightweight High-Performance)
  agent_o4_mini:
    <<: *ollama-base
    container_name: agent_o4_mini
    environment:
      - OLLAMA_MODEL=gpt-o4-mini
    deploy:
      resources:
        limits:
          memory: "4g"
          cpus: "1"

  # GPT-O4-Mini-High Agent (Enhanced Accuracy)
  agent_o4_mini_high:
    <<: *ollama-base
    container_name: agent_o4_mini_high
    environment:
      - OLLAMA_MODEL=gpt-o4-mini-high
    deploy:
      resources:
        limits:
          memory: "6g"
          cpus: "2"

  # Model Quantization Tool
  quantize:
    image: ollama/quantize:latest
    container_name: ollama_quantize
    entrypoint:
      - "sh"
      - "-c"
      - "while true; do sleep 3600; done"
    volumes:
      - ollama_data:/root/.ollama
    logging: *common-logging
    restart: "on-failure"
    env_file:
      - .env
    deploy:
      resources:
        limits:
          memory: "2g"
          cpus: "0.5"

  # Vector Database (Qdrant)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: vector_db
    ports:
      - "6333:6333"
    volumes:
      - qdrant_storage:/qdrant/storage
    logging: *common-logging
    restart: unless-stopped
    env_file:
      - .env
    deploy:
      resources:
        limits:
          memory: "512m"
          cpus: "0.25"

  # Qdrant Backup Service
  qdrant_backup:
    image: qdrant/qdrant-backup:latest
    container_name: qdrant_backup
    entrypoint: ["sh", "-c", "backup.sh"]
    environment:
      - QDRANT_API_KEY=${QDRANT_API_KEY}
    volumes:
      - qdrant_storage:/qdrant/storage
    logging: *common-logging
    restart: "on-failure"
    env_file:
      - .env
    deploy:
      resources:
        limits:
          memory: "1g"
          cpus: "0.25"

  # n8n Workflow Engine
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n_mcp
    env_file:
      - .env
    ports:
      - "5678:5678"
    volumes:
      - n8n_data:/home/node/.n8n
    depends_on:
      - postgres
    logging: *common-logging
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: "2g"
          cpus: "1"

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: postgres_db
    env_file:
      - .env
    volumes:
      - postgres_data:/var/lib/postgresql/data
    logging: *common-logging
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: "1g"
          cpus: "0.5"

  # Traefik Reverse Proxy & SSL
  traefik:
    image: traefik:latest
    container_name: traefik_proxy
    env_file:
      - .env
    command:
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --providers.docker=true
      - --certificatesresolvers.le.acme.tlschallenge=true
      - --certificatesresolvers.le.acme.email=${LETSENCRYPT_EMAIL}
      - --certificatesresolvers.le.acme.storage=/letsencrypt/acme.json
      - --api.dashboard=true
      - --api.insecure=false
      - --entrypoints.websecure.auth.basic.users=${TRAEFIK_DASH_USER}:${TRAEFIK_DASH_PASS}
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik_cert:/letsencrypt
    logging: *common-logging
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: "500m"
          cpus: "0.2"

  # InfluxDB (Time-series Metrics)
  influxdb:
    image: influxdb:2.7
    container_name: influx_db
    env_file:
      - .env
    ports:
      - "8086:8086"
    volumes:
      - influxdb_data:/var/lib/influxdb2
    environment:
      - INFLUXDB_ADMIN_USER=${INFLUXDB_ADMIN_USER}
      - INFLUXDB_ADMIN_PASSWORD=${INFLUXDB_ADMIN_PASSWORD}
      - INFLUXDB_BUCKET=${INFLUXDB_BUCKET}
      - INFLUXDB_ORG=${INFLUXDB_ORG}
    logging: *common-logging
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: "500m"
          cpus: "0.5"

  # Grafana (Visualization & Alerting)
  grafana:
    image: grafana/grafana:latest
    container_name: grafana_dashboard
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - influxdb
    logging: *common-logging
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: "500m"
          cpus: "0.5"

volumes:
  ollama_data:
  n8n_data:
  postgres_data:
  traefik_cert:
  influxdb_data:
  grafana_data:
  qdrant_storage:
